{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kjs6397/.conda/envs/mamba_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [02:06<00:00,  2.89it/s]\n",
      "Fold 1 Testing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46/46 [00:06<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUROC: 0.6037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83       270\n",
      "           1       0.44      0.22      0.29        97\n",
      "\n",
      "    accuracy                           0.72       367\n",
      "   macro avg       0.60      0.56      0.56       367\n",
      "weighted avg       0.68      0.72      0.68       367\n",
      "\n",
      "Evaluating fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 403/403 [02:36<00:00,  2.58it/s]\n",
      "Fold 2 Testing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 AUROC: 0.5843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       333\n",
      "           1       0.34      0.33      0.34        70\n",
      "\n",
      "    accuracy                           0.77       403\n",
      "   macro avg       0.60      0.60      0.60       403\n",
      "weighted avg       0.77      0.77      0.77       403\n",
      "\n",
      "Evaluating fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 324/324 [02:11<00:00,  2.47it/s]\n",
      "Fold 3 Testing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [00:02<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 AUROC: 0.7037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.80       260\n",
      "           1       0.34      0.53      0.42        64\n",
      "\n",
      "    accuracy                           0.71       324\n",
      "   macro avg       0.61      0.64      0.61       324\n",
      "weighted avg       0.76      0.71      0.73       324\n",
      "\n",
      "Evaluating fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 410/410 [02:30<00:00,  2.72it/s]\n",
      "Fold 4 Testing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:03<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 AUROC: 0.6408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86       337\n",
      "           1       0.40      0.44      0.42        73\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.64      0.65      0.64       410\n",
      "weighted avg       0.79      0.78      0.78       410\n",
      "\n",
      "Evaluating fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 306/306 [01:42<00:00,  3.00it/s]\n",
      "Fold 5 Testing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:03<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 AUROC: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       261\n",
      "           1       0.31      0.24      0.28        45\n",
      "\n",
      "    accuracy                           0.81       306\n",
      "   macro avg       0.59      0.58      0.58       306\n",
      "weighted avg       0.79      0.81      0.80       306\n",
      "\n",
      "Class specific metrics across 5 folds\n",
      "       Class Precision (mean±std) Recall (mean±std) F1-Score (mean±std)\n",
      "0 (Negative)      0.8477 ± 0.0433   0.8561 ± 0.0566     0.8498 ± 0.0310\n",
      "1 (Positive)      0.3667 ± 0.0439   0.3518 ± 0.1184     0.3466 ± 0.0604\n",
      "Ensembl summary\n",
      "             Model           AUROC     Sensitivity     Specificity       Precision        F1-Score\n",
      "Modified3DDenseNet 0.6372 ± 0.0415 0.3518 ± 0.1184 0.8561 ± 0.0566 0.3667 ± 0.0439 0.3466 ± 0.0604\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityRanged, Resized, ToTensord\n",
    "from monai.data import DataLoader, CacheDataset\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Modified3DDenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        from monai.networks.nets import DenseNet121\n",
    "        self.densenet = DenseNet121(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=num_classes\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n",
    "\n",
    "def load_data(labels_file, data_path, task):\n",
    "    df = pd.read_csv(labels_file, index_col=0)\n",
    "    df = df[df[task].notna()]\n",
    "    df['path'] = f'{data_path}/' + df['Patient'].astype(str) + '/' + df['filename'].astype(str) + '.nii.gz'\n",
    "    df = df[['path', task, 'Patient']]\n",
    "    file_list = df['path'].values\n",
    "    labels = df[task].astype(int).values\n",
    "    patient_ids = df['Patient'].values\n",
    "    return file_list, labels, patient_ids\n",
    "\n",
    "def prepare_data(files, labels):\n",
    "    return [{\"image\": file_path, \"label\": label} for file_path, label in zip(files, labels)]\n",
    "\n",
    "\n",
    "data_path = \"/projects/b1038/Pulmonary/ksenkow/CLAD_serial_CT/data/6multiplied\"\n",
    "labels_file = \"/projects/b1038/Pulmonary/ksenkow/CLAD_serial_CT/data/v2_analysis/01gather_data/mortality_metadata.csv\"\n",
    "logdir = \"../../05mortality_analysis/DenseNet/logs/DenseNet-2/densenet_mortality_12m_20250308_165417\" \n",
    "\n",
    "task = \"mortality_12m\"\n",
    "transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "    Resized(keys=[\"image\"], spatial_size=(128, 128, 128)),\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# prepare data\n",
    "file_list, labels, patient_ids = load_data(labels_file, data_path, task)\n",
    "df_patients = pd.DataFrame({\"patient\": patient_ids, \"label\": labels})\n",
    "patient_labels = df_patients.groupby(\"patient\")[\"label\"].max()\n",
    "unique_patients = patient_labels.index.to_numpy()\n",
    "unique_labels = patient_labels.values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_auroc = []\n",
    "fold_precision_class0 = []\n",
    "fold_precision_class1 = []\n",
    "fold_recall_class0 = []\n",
    "fold_recall_class1 = []\n",
    "fold_f1_class0 = []\n",
    "fold_f1_class1 = []\n",
    "\n",
    "# evaluation loop\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(unique_patients, unique_labels)):\n",
    "    print(f\"Evaluating fold {fold+1}/5\")\n",
    "    test_patients = unique_patients[test_idx]\n",
    "    test_mask = np.isin(patient_ids, test_patients)\n",
    "    test_files = file_list[test_mask]\n",
    "    test_labels = labels[test_mask]\n",
    "    \n",
    "    test_data = prepare_data(test_files, test_labels)\n",
    "    test_ds = CacheDataset(data=test_data, transform=transforms, cache_rate=1.0, num_workers=8)\n",
    "    test_loader = DataLoader(test_ds, batch_size=8, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    # load the best model for this fold\n",
    "    model = Modified3DDenseNet(num_classes=2).to(device)\n",
    "    model_path = os.path.join(logdir, f\"fold_{fold}_best_model.pth\")\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Fold {fold+1} Testing\"):\n",
    "            inputs = batch[\"image\"].to(device)\n",
    "            labels_batch = batch[\"label\"].to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_outputs.append(outputs.cpu())\n",
    "            all_labels.append(labels_batch.cpu())\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    probs = torch.softmax(all_outputs, dim=1).numpy()\n",
    "    preds = probs.argmax(axis=1)\n",
    "    true_labels = all_labels.numpy()\n",
    "    \n",
    "    # compute AUROC using the positive class (index 1).\n",
    "    auroc = roc_auc_score(true_labels, probs[:, 1])\n",
    "    fold_auroc.append(auroc)\n",
    "    \n",
    "    # compute per-class precision, recall, and F1.\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average=None)\n",
    "    fold_precision_class0.append(precision[0])\n",
    "    fold_precision_class1.append(precision[1])\n",
    "    fold_recall_class0.append(recall[0])\n",
    "    fold_recall_class1.append(recall[1])\n",
    "    fold_f1_class0.append(f1[0])\n",
    "    fold_f1_class1.append(f1[1])\n",
    "    \n",
    "    print(f\"Fold {fold+1} AUROC: {auroc:.4f}\")\n",
    "    print(classification_report(true_labels, preds))\n",
    "\n",
    "# ensemble metrics (mean ± std)\n",
    "mean_auroc, std_auroc = np.mean(fold_auroc), np.std(fold_auroc)\n",
    "mean_prec0, std_prec0 = np.mean(fold_precision_class0), np.std(fold_precision_class0)\n",
    "mean_prec1, std_prec1 = np.mean(fold_precision_class1), np.std(fold_precision_class1)\n",
    "mean_recall0, std_recall0 = np.mean(fold_recall_class0), np.std(fold_recall_class0)\n",
    "mean_recall1, std_recall1 = np.mean(fold_recall_class1), np.std(fold_recall_class1)\n",
    "mean_f1_0, std_f1_0 = np.mean(fold_f1_class0), np.std(fold_f1_class0)\n",
    "mean_f1_1, std_f1_1 = np.mean(fold_f1_class1), np.std(fold_f1_class1)\n",
    "\n",
    "table_data_classes = {\n",
    "    \"Class\": [\"0 (Negative)\", \"1 (Positive)\"],\n",
    "    \"Precision (mean±std)\": [\n",
    "        f\"{mean_prec0:.4f} ± {std_prec0:.4f}\",\n",
    "        f\"{mean_prec1:.4f} ± {std_prec1:.4f}\"\n",
    "    ],\n",
    "    \"Recall (mean±std)\": [\n",
    "        f\"{mean_recall0:.4f} ± {std_recall0:.4f}\",\n",
    "        f\"{mean_recall1:.4f} ± {std_recall1:.4f}\"\n",
    "    ],\n",
    "    \"F1-Score (mean±std)\": [\n",
    "        f\"{mean_f1_0:.4f} ± {std_f1_0:.4f}\",\n",
    "        f\"{mean_f1_1:.4f} ± {std_f1_1:.4f}\"\n",
    "    ]\n",
    "}\n",
    "df_classes = pd.DataFrame(table_data_classes)\n",
    "print(\"Class specific metrics across 5 folds\")\n",
    "print(df_classes.to_string(index=False))\n",
    "\n",
    "# ensembl summary\n",
    "summary_data = {\n",
    "    \"Model\": [\"Modified3DDenseNet\"],\n",
    "    \"AUROC\": [f\"{mean_auroc:.4f} ± {std_auroc:.4f}\"],\n",
    "    \"Sensitivity\": [f\"{mean_recall1:.4f} ± {std_recall1:.4f}\"],  # recall for class 1\n",
    "    \"Specificity\": [f\"{mean_recall0:.4f} ± {std_recall0:.4f}\"],  # recall for class 0\n",
    "    \"Precision\": [f\"{mean_prec1:.4f} ± {std_prec1:.4f}\"],         # precision for class 1\n",
    "    \"F1-Score\": [f\"{mean_f1_1:.4f} ± {std_f1_1:.4f}\"]\n",
    "}\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"Ensembl summary\")\n",
    "print(df_summary.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_venv",
   "language": "python",
   "name": "mamba_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
